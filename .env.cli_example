# Multi-Agent Coder - CLI Edition Configuration
# NO API KEYS NEEDED! Just point to your installed CLI tools.

# ============================================
# AI CLI Tool Commands
# ============================================

# Claude CLI
# Install: irm https://claude.ai/install.ps1 | iex (Windows)
#         or curl https://claude.ai/install.sh | sh (Linux/Mac)
CLAUDE_CLI=claude

# Google Gemini CLI
# Install: npm install -g @google/gemini-cli
GEMINI_CLI=gemini

# OpenAI Codex CLI
# Install: npm i -g @openai/codex
CODEX_CLI=codex

# GPT-4 CLI (if available)
GPT4_CLI=gpt4

# ============================================
# Custom CLI Tools
# ============================================
# You can add custom CLI tools here
# Format: CUSTOM_CLI_<NAME>=/path/to/cli-tool

# Example:
# CUSTOM_CLI_LLAMACPP=/usr/local/bin/llama-cli
# CUSTOM_CLI_OLLAMA=/usr/local/bin/ollama
# CUSTOM_CLI_LOCALAI=/usr/local/bin/localai

# ============================================
# System Settings
# ============================================

# Maximum number of clarifying questions to ask
MAX_QUESTIONS=3

# Request timeout in seconds
REQUEST_TIMEOUT=120

# Enable debug logging
DEBUG=false

# Auto-detect CLI tools on startup
AUTO_DETECT_CLIS=true

# Enabled agents (comma-separated, or "auto" for auto-detect)
# Options: auto, claude, gemini, openai, codex, gpt4, or custom names
ENABLED_AGENTS=auto

# ============================================
# Example Custom CLI Tool Configuration
# ============================================

# For Ollama (local LLM):
# CUSTOM_CLI_OLLAMA=ollama
# And in your code, you would use GenericCLIAgent with command="ollama"

# For LocalAI:
# CUSTOM_CLI_LOCALAI=localai-cli

# For llama.cpp:
# CUSTOM_CLI_LLAMACPP=./llama-cli
